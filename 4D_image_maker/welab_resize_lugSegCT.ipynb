{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0bab767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53486866",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_path = 'E:/data/Resize_nature_wulab'\n",
    "#lung_path = '/Data/Resize_nature_wulab'\n",
    "\n",
    "save_path  =  'E:/data/Histology/'\n",
    "#save_path  =  'Data/Histology/nature'\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6307754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_list = [i for i in os.listdir(lung_path) if i.endswith('ct.nii.gz')]\n",
    "bias = 4000\n",
    "for i,ct in enumerate(ct_list):\n",
    "    print('{} .  {}'.format(i+1, ct))\n",
    "    whole_path_ct = os.path.join(lung_path, ct)\n",
    "    whole_path_seg = os.path.join(lung_path, ct[:-9]+'lung.nii.gz')\n",
    "    \n",
    "    print(whole_path_ct)\n",
    "    print(whole_path_seg)\n",
    "    # load lung and normalize \n",
    "    lung_h = nib.load(whole_path_ct)\n",
    "    lung = lung_h.get_fdata()\n",
    "    lung = lung + bias\n",
    "    #lung = normalize(lung)\n",
    "    print('ct loaded')\n",
    "    \n",
    "    #load seg\n",
    "    seg_h = nib.load(whole_path_seg)\n",
    "    seg = seg_h.get_fdata()\n",
    "    print('seg loaded')\n",
    "    \n",
    "    # lung* seg\n",
    "    lung_seg = lung*seg\n",
    "    lung_seg = lung_seg - bias\n",
    "\n",
    "    img_NIFTI = nib.Nifti1Image(lung_seg, lung_h.affine )\n",
    "    img_NIFTI.to_filename(os.path.join(save_path,ct))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_list = [i for i in os.listdir(lung_path) if i.endswith('ct.nii.gz')]\n",
    "print(len(ct_list))\n",
    "ct_list[0][:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6736956",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc5b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 9\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "print(confusion_matrix)\n",
    "To get the per-class accuracy:\n",
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nb_classes = 9\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "# Confusion matrix\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "print(conf_mat)\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print(class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat=confusion_matrix([1, 0, 1, 0], [1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "837156ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "path = 'E:/data/Histology/nature_4d' #'/Data/Histology/nature_4d'\n",
    "df = pd.read_csv( 'Patient_list_modified.csv') #pd.read_csv( '/Data/Histology/Patient_list_modified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c11ca181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_01_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_02_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_04_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_05_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_06_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_07_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\NSCLC_Hugo_89_pt_08_ct.nii.gz\n",
      "E:/data/Histology/nature_4d\\Stanford_stageIII_Smith,Basil_ct.nii.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MSALEH~1\\ONEDRI~1.ORG\\DOCUME~1\\MOBAXT~1\\slash\\tmp/ipykernel_24448/959180118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(count, end=' ')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mp_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_ct.nii.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnot_there\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "p_list = df['ID'].tolist()\n",
    "not_there = []\n",
    "count = 0\n",
    "for p in p_list:\n",
    "    #print(count, end=' ')\n",
    "    count += 1\n",
    "    p_path = os.path.join(path, p + '_ct.nii.gz')\n",
    "    if not exists(p_path):\n",
    "        not_there.append(p_path)\n",
    "        print(p_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1dca0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_01_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_02_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_04_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_05_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_06_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_07_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\NSCLC_Hugo_89_pt_08_ct.nii.gz',\n",
       " 'E:/data/Histology/nature_4d\\\\Stanford_stageIII_Smith,Basil_ct.nii.gz']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74d0947f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
